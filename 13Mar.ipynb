{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c97a6231-21f2-41fe-9a27-5945573c01c4",
   "metadata": {},
   "source": [
    "# stats 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0be1bbd-f01b-4a56-91da-1425fe5386b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=\"13MarInfo.log\", level=logging.INFO, format=\"%(asctime)s %(name)s %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f85ed87-91f2-4772-8fb9-54485b13e998",
   "metadata": {},
   "source": [
    "# answer 1\n",
    "\"\"\"\n",
    "ANOVA (Analysis of Variance) is a statistical method used to compare the means of two or more groups. The \n",
    "assumptions required to use ANOVA are as follows:\n",
    "\n",
    "- Absence of outliers: Outlying score should be removed from data set.\n",
    "\n",
    "- Independence: The observations within each group must be independent of each other.\n",
    "\n",
    "- Normality: The distribution of the data within each group must be approximately normal.\n",
    "\n",
    "- Homogeneity of variance: The variance of the data within each group must be approximately equal.\n",
    "\n",
    "Examples of violations that could impact the validity of ANOVA results are:\n",
    "\n",
    "- Non-independence: If the observations within each group are not independent, such as in repeated measures\n",
    "designs, ANOVA results may be invalid.\n",
    "\n",
    "- Non-normality: If the distribution of the data within each group is not approximately normal, ANOVA results\n",
    "may be unreliable. For example, if the data is heavily skewed or has outliers, the assumptions of normality \n",
    "may be violated.\n",
    "\n",
    "- Heterogeneity of variance: If the variance of the data within each group is not approximately equal, ANOVA \n",
    "results may be biased. For example, if the data from one group has much larger variance than the others, \n",
    "ANOVA may incorrectly conclude that there are significant differences between the groups.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd29818-52c5-4cdc-a96e-b4bdcccacd90",
   "metadata": {},
   "source": [
    "# answer 2\n",
    "\"\"\"\n",
    "ANOVA (Analysis of Variance) is a statistical technique used to compare the means of two or more groups or treatments. There are several types of ANOVA, including one-way ANOVA, repeated measures ANOVA, and factorial ANOVA.\n",
    "\n",
    "- **One-way ANOVA**:\n",
    "\n",
    "One-way ANOVA is used to compare the means of three or more independent groups that are not related to each other. It tests whether the means of the groups are significantly different from each other. \n",
    "**For example, if we wanted to compare the mean test scores of students who studied for 0 hours, 1 hour, 2 hours, or 3 hours, a one-way ANOVA could be used to determine if there is a statistically significant difference between the mean test scores of these groups.**\n",
    "\n",
    "- **Repeated measures ANOVA**:\n",
    "\n",
    "Repeated measures ANOVA is used when we want to compare the means of a single group or subject under different conditions. This is often used in studies where the same group of participants is tested multiple times, such as in a longitudinal study. The repeated measures ANOVA takes into account the correlation between the repeated measures and provides a more powerful test compared to a series of independent t-tests.\n",
    "\n",
    "- **Factorial ANOVA**:\n",
    "\n",
    "Factorial ANOVA is used when we want to test the effects of two or more independent variables on a dependent variable. It tests whether there is a significant main effect of each independent variable and whether there is an interaction effect between the independent variables.\n",
    "**For example, if we were interested in testing the effect of both gender and age on salary, a two-way factorial ANOVA could be used to determine if there is a significant main effect of gender and age, as well as an interaction effect between the two variables.**\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb44aaf8-96f9-48e4-b6f8-3310bbb63050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe partitioning of variance in ANOVA refers to the division of the total variance of a dependent variable\\ninto different components, each of which is associated with a specific source of variation. \\n\\nThe total variance in the dependent variable can be partitioned into two components: the variance between \\ngroups (due to differences between groups) and the variance within groups (due to individual differences \\nwithin each group). The ratio of the between-group variance to the within-group variance is used to determine\\nthe statistical significance of the differences between groups.\\n\\nUnderstanding the partitioning of variance in ANOVA is important because it allows researchers to identify \\nthe sources of variation that contribute to the differences between groups. This information can be used to\\ngain insights into the factors that are associated with the dependent variable and to design more effective\\ninterventions or treatments. Additionally, partitioning of variance allows researchers to test the statistical\\nsignificance of the differences between groups, which is essential for drawing valid conclusions about the\\nrelationships between variables.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 3\n",
    "\"\"\"\n",
    "The partitioning of variance in ANOVA refers to the division of the total variance of a dependent variable\n",
    "into different components, each of which is associated with a specific source of variation. \n",
    "\n",
    "The total variance in the dependent variable can be partitioned into two components: the variance between \n",
    "groups (due to differences between groups) and the variance within groups (due to individual differences \n",
    "within each group). The ratio of the between-group variance to the within-group variance is used to determine\n",
    "the statistical significance of the differences between groups.\n",
    "\n",
    "Understanding the partitioning of variance in ANOVA is important because it allows researchers to identify \n",
    "the sources of variation that contribute to the differences between groups. This information can be used to\n",
    "gain insights into the factors that are associated with the dependent variable and to design more effective\n",
    "interventions or treatments. Additionally, partitioning of variance allows researchers to test the statistical\n",
    "significance of the differences between groups, which is essential for drawing valid conclusions about the\n",
    "relationships between variables.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7051502-1a9b-4d73-808a-c3e4099a7088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 442.20027347393636\n",
      "SSE: 29.999927882554044\n",
      "SSR: 412.2003455913823\n"
     ]
    }
   ],
   "source": [
    "# answer 4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "#generate random data\n",
    "np.random.seed(123)\n",
    "data = pd.DataFrame({'group': np.random.choice(['A', 'B', 'C'], size=90),\n",
    "                     'value': np.random.normal(loc=10, scale=2, size=90)})\n",
    "\n",
    "group_means = data.groupby('group')['value'].mean()\n",
    "grand_mean = data['value'].mean()\n",
    "SST = ((data['value'] - grand_mean) ** 2).sum()\n",
    "SSE = ((group_means - grand_mean) ** 2 * data['group'].value_counts()).sum()\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\", SSE)\n",
    "print(\"SSR:\", SSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4488f9e-7932-4ea7-97e0-1bffa45e35cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effects:\n",
      "     sum_sq   df         F\n",
      "A  0.971609  1.0  0.666667\n",
      "B  0.971609  1.0  0.666667\n",
      "\n",
      "Interaction Effect:\n",
      "sum_sq    0.804310\n",
      "df        1.000000\n",
      "F         0.551875\n",
      "Name: A:B, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# answwer 5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "np.random.seed(123)\n",
    "df = pd.DataFrame({'A': np.repeat(['a', 'b'], 25),\n",
    "                   'B': np.repeat(['x', 'y'], 25),\n",
    "                   'score': np.random.normal(0, 1, 50)})\n",
    "\n",
    "model = ols('score ~ A + B + A:B', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "main_effects = anova_table[['sum_sq', 'df', 'F']].iloc[:2]\n",
    "interaction_effect = anova_table[['sum_sq', 'df', 'F']].iloc[2]\n",
    "\n",
    "print('Main Effects:')\n",
    "print(main_effects)\n",
    "print('\\nInteraction Effect:')\n",
    "print(interaction_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c07a3f7d-9de1-4dcc-a99d-b4f771da6331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIf we conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, \\nwe can conclude that there is a significant difference between the means of the groups.\\n\\nThe F-statistic measures the ratio of the variance between groups to the variance within groups.\\nA large F-statistic indicates that the variance between groups is much greater than the variance\\nwithin groups, suggesting that there is a significant difference between the means of the groups.\\n\\nThe p-value of 0.02 indicates that there is strong evidence against the null hypothesis of equal \\nmeans, assuming a significance level of 0.05. Therefore, we can reject the null hypothesis and \\nconclude that there is a significant difference between the means of the groups.\\n\\nTo interpret these results, we can compare the means of the groups using post-hoc tests, such as \\nTukey's HSD (honestly significant difference) test, to determine which specific groups differ\\nsignificantly from each other. Additionally, we can report effect size measures, such as eta-squared\\nor Cohen's d, to quantify the magnitude of the observed differences between the groups.\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 6\n",
    "\"\"\"\n",
    "If we conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, \n",
    "we can conclude that there is a significant difference between the means of the groups.\n",
    "\n",
    "The F-statistic measures the ratio of the variance between groups to the variance within groups.\n",
    "A large F-statistic indicates that the variance between groups is much greater than the variance\n",
    "within groups, suggesting that there is a significant difference between the means of the groups.\n",
    "\n",
    "The p-value of 0.02 indicates that there is strong evidence against the null hypothesis of equal \n",
    "means, assuming a significance level of 0.05. Therefore, we can reject the null hypothesis and \n",
    "conclude that there is a significant difference between the means of the groups.\n",
    "\n",
    "To interpret these results, we can compare the means of the groups using post-hoc tests, such as \n",
    "Tukey's HSD (honestly significant difference) test, to determine which specific groups differ\n",
    "significantly from each other. Additionally, we can report effect size measures, such as eta-squared\n",
    "or Cohen's d, to quantify the magnitude of the observed differences between the groups.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c19933e-36b4-465f-9761-1df54a6359f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHandling missing data in a repeated measures ANOVA can be challenging, as missing data can introduce\\nbias and reduce the power of the analysis. There are several methods to handle missing data in a repeated\\nmeasures ANOVA, and the choice of method can have different consequences depending on the type and amount\\nof missing data.\\n\\nHere are some common methods to handle missing data in a repeated measures ANOVA:\\n\\nPairwise deletion: This method involves excluding cases that have missing data on any of the variables. \\nWhile this method is simple to implement, it can reduce the sample size and introduce bias if the missing\\ndata are not missing completely at random.\\n\\nListwise deletion: This method involves excluding cases that have missing data on any of the variables\\nused in the analysis. While this method avoids bias due to missing data, it can reduce the sample size\\nand introduce bias if the missing data are not missing completely at random.\\n\\nImputation: This method involves estimating the missing values based on the observed values and using \\nthese estimates in the analysis. There are several types of imputation methods, such as mean imputation, \\nregression imputation, and multiple imputation. While imputation can preserve the sample size and avoid\\nbias due to missing data, it can introduce bias if the imputation model is misspecified or if the \\nmissing data are not missing at random.\\n\\nMaximum likelihood estimation: This method involves estimating the model parameters using all \\navailable data, including the cases with missing data. While this method can be computationally intensive,\\nit can provide unbiased estimates of the model parameters under certain assumptions about the missing data\\nmechanism.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 7\n",
    "\"\"\"\n",
    "Handling missing data in a repeated measures ANOVA can be challenging, as missing data can introduce\n",
    "bias and reduce the power of the analysis. There are several methods to handle missing data in a repeated\n",
    "measures ANOVA, and the choice of method can have different consequences depending on the type and amount\n",
    "of missing data.\n",
    "\n",
    "Here are some common methods to handle missing data in a repeated measures ANOVA:\n",
    "\n",
    "Pairwise deletion: This method involves excluding cases that have missing data on any of the variables. \n",
    "While this method is simple to implement, it can reduce the sample size and introduce bias if the missing\n",
    "data are not missing completely at random.\n",
    "\n",
    "Listwise deletion: This method involves excluding cases that have missing data on any of the variables\n",
    "used in the analysis. While this method avoids bias due to missing data, it can reduce the sample size\n",
    "and introduce bias if the missing data are not missing completely at random.\n",
    "\n",
    "Imputation: This method involves estimating the missing values based on the observed values and using \n",
    "these estimates in the analysis. There are several types of imputation methods, such as mean imputation, \n",
    "regression imputation, and multiple imputation. While imputation can preserve the sample size and avoid\n",
    "bias due to missing data, it can introduce bias if the imputation model is misspecified or if the \n",
    "missing data are not missing at random.\n",
    "\n",
    "Maximum likelihood estimation: This method involves estimating the model parameters using all \n",
    "available data, including the cases with missing data. While this method can be computationally intensive,\n",
    "it can provide unbiased estimates of the model parameters under certain assumptions about the missing data\n",
    "mechanism.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d602fe84-5890-477d-9b88-f4b47a06b29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPost-hoc tests are used after an ANOVA to determine which specific groups differ significantly\\nfrom each other. Here are some common post-hoc tests used after ANOVA, along with when and why\\nwe would use them:\\n\\nTukey's HSD (Honestly Significant Difference) test: This test is used when we have conducted an\\nANOVA with more than two groups and want to compare all possible pairwise differences between the groups.\\nIt controls the family-wise error rate, making it a conservative test.\\n\\nBonferroni test: This test is used when we have conducted multiple pairwise comparisons and want to \\ncontrol the overall Type I error rate. It is more conservative than Tukey's test, but it is less powerful.\\n\\nScheffe's test: This test is used when we have conducted an ANOVA with more than two groups and want to \\ncompare all possible pairwise differences between the groups while controlling the family-wise error rate.\\nIt is more powerful than Tukey's test but is more conservative than the Bonferroni test.\\n\\nDunnett's test: This test is used when we have one control group and want to compare it with each of \\nthe other groups. It controls the overall Type I error rate while allowing for multiple comparisons \\nwith a single control group.\\n\\nGames-Howell test: This test is used when the assumption of equal variances is violated, and we want \\nto compare all possible pairwise differences between the groups. It is more powerful than Tukey's test\\nwhen the assumption of equal variances is violated.\\n\\nKruskal-Wallis test: This test is a non-parametric alternative to ANOVA and is used when the assumption\\nof normality is violated. It tests whether the medians of the groups differ significantly and can be \\nfollowed by post-hoc tests such as Dunn's test.\\n\\nAn example situation where a post-hoc test might be necessary is when we conduct an ANOVA to compare\\nthe mean scores of three different teaching methods in a classroom. If the ANOVA shows a significant \\ndifference between the means, we might want to use Tukey's HSD test to determine which specific teaching\\nmethods are significantly different from each other. This would help us to identify which teaching method \\nis most effective and can inform future teaching strategies.\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 8\n",
    "\"\"\"\n",
    "Post-hoc tests are used after an ANOVA to determine which specific groups differ significantly\n",
    "from each other. Here are some common post-hoc tests used after ANOVA, along with when and why\n",
    "we would use them:\n",
    "\n",
    "Tukey's HSD (Honestly Significant Difference) test: This test is used when we have conducted an\n",
    "ANOVA with more than two groups and want to compare all possible pairwise differences between the groups.\n",
    "It controls the family-wise error rate, making it a conservative test.\n",
    "\n",
    "Bonferroni test: This test is used when we have conducted multiple pairwise comparisons and want to \n",
    "control the overall Type I error rate. It is more conservative than Tukey's test, but it is less powerful.\n",
    "\n",
    "Scheffe's test: This test is used when we have conducted an ANOVA with more than two groups and want to \n",
    "compare all possible pairwise differences between the groups while controlling the family-wise error rate.\n",
    "It is more powerful than Tukey's test but is more conservative than the Bonferroni test.\n",
    "\n",
    "Dunnett's test: This test is used when we have one control group and want to compare it with each of \n",
    "the other groups. It controls the overall Type I error rate while allowing for multiple comparisons \n",
    "with a single control group.\n",
    "\n",
    "Games-Howell test: This test is used when the assumption of equal variances is violated, and we want \n",
    "to compare all possible pairwise differences between the groups. It is more powerful than Tukey's test\n",
    "when the assumption of equal variances is violated.\n",
    "\n",
    "Kruskal-Wallis test: This test is a non-parametric alternative to ANOVA and is used when the assumption\n",
    "of normality is violated. It tests whether the medians of the groups differ significantly and can be \n",
    "followed by post-hoc tests such as Dunn's test.\n",
    "\n",
    "An example situation where a post-hoc test might be necessary is when we conduct an ANOVA to compare\n",
    "the mean scores of three different teaching methods in a classroom. If the ANOVA shows a significant \n",
    "difference between the means, we might want to use Tukey's HSD test to determine which specific teaching\n",
    "methods are significantly different from each other. This would help us to identify which teaching method \n",
    "is most effective and can inform future teaching strategies.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afed5be4-493a-4e7d-a53e-44b2f0acfb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 25.44\n",
      "p-value: 0.0000\n",
      "Reject the NUll hypothesis \n",
      " Atleast one of the sample mean is not equal\n"
     ]
    }
   ],
   "source": [
    "# answer 9\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "h0=\"The means are equal\"\n",
    "ha=\"Atleast one of the sample mean is not equal\"\n",
    "\n",
    "alpha=0.05\n",
    "\n",
    "# Generate random weight loss data for each diet\n",
    "\"\"\"np.random.seed(1234) sets the seed for the random number generator, ensuring that the same random values are generated each time \n",
    "the code is run with the same seed.\n",
    "np.random.normal(mean, standard deviation, size) generates random numbers from a normal distribution with the specified mean, standard deviation,\n",
    "and size. \n",
    "\"\"\"\n",
    "np.random.seed(1234)\n",
    "diet_a = np.random.normal(10, 2, size=50)\n",
    "diet_b = np.random.normal(8, 3, size=50)\n",
    "diet_c = np.random.normal(12, 4, size=50)\n",
    "# print(diet_a,diet_b,diet_c)\n",
    "\n",
    "# Conduct one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_a, diet_b, diet_c)\n",
    "\n",
    "# Print results\n",
    "print(\"F-statistic: {:.2f}\".format(f_statistic))\n",
    "print(\"p-value: {:.4f}\".format(p_value))\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the NUll hypothesis \\n Atleast one of the sample mean is not equal\")\n",
    "else:\n",
    "    print(\"Fail to reject the Null Hypotheses \\n The means are equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e39cd076-679b-4601-9774-532af83d8413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-way ANOVA results:\n",
      "F-statistic: 65.41053310163127\n",
      "p-value: 4.589260705868439e-18\n",
      "\n",
      "Tukey's HSD post-hoc test results:\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      "group1 group2 meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------\n",
      "     A      B  -7.2333    0.0 -9.5096  -4.957   True\n",
      "     A      C   3.4667 0.0014  1.1904   5.743   True\n",
      "     B      C     10.7    0.0  8.4237 12.9763   True\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# answer 10\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate some sample data\n",
    "store_a_sales = [35, 37, 29, 42, 44, 30, 38, 39, 41, 36, 28, 32, 43, 37, 33, 36, 30, 45, 39, 42, 34, 38, 43, 31, 40, 44, 37, 40, 33, 35]\n",
    "store_b_sales = [29, 31, 28, 25, 36, 27, 33, 24, 32, 30, 26, 30, 35, 29, 33, 28, 27, 32, 30, 34, 25, 28, 29, 26, 36, 31, 30, 27, 31, 32]\n",
    "store_c_sales = [40, 42, 37, 39, 45, 38, 42, 43, 41, 39, 36, 44, 43, 42, 39, 41, 38, 44, 36, 43, 39, 42, 40, 44, 38, 42, 36, 43, 41, 38]\n",
    "\n",
    "# Combine the data into a single DataFrame\n",
    "sales_data = pd.DataFrame({'sales': store_a_sales + store_b_sales + store_c_sales,\n",
    "                           'store': ['A']*len(store_a_sales) + ['B']*len(store_b_sales) + ['C']*len(store_c_sales)})\n",
    "\n",
    "# Conduct one-way ANOVA\n",
    "f_stat, p_val = stats.f_oneway(store_a_sales, store_b_sales, store_c_sales)\n",
    "print('One-way ANOVA results:')\n",
    "print('F-statistic:', f_stat)\n",
    "print('p-value:', p_val)\n",
    "\n",
    "# Conduct post-hoc test (Tukey's HSD)\n",
    "tukey_results = pairwise_tukeyhsd(sales_data['sales'], sales_data['store'])\n",
    "print('\\nTukey\\'s HSD post-hoc test results:')\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ec344dc-cef2-4550-be75-981b6dc41fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -3.0316172004188147\n",
      "p-value: 0.0027577299763983324\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "control experimental   4.5336 0.0028 1.5846 7.4826   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# answer 11\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(123)\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_scores = np.random.normal(loc=75, scale=10, size=100)\n",
    "\n",
    "# Conduct two-sample t-test\n",
    "t, p = stats.ttest_ind(control_scores, experimental_scores)\n",
    "print(\"t-statistic:\", t)\n",
    "print(\"p-value:\", p)\n",
    "\n",
    "# Conduct post-hoc test (Tukey's HSD)\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "if p < 0.05:\n",
    "    # Combine the data into a single DataFrame\n",
    "    data = pd.DataFrame({'score': np.concatenate((control_scores, experimental_scores)),\n",
    "                         'group': ['control']*100 + ['experimental']*100})\n",
    "\n",
    "    # Conduct Tukey's HSD test\n",
    "    tukey_results = pairwise_tukeyhsd(data['score'], data['group'])\n",
    "    print(tukey_results)\n",
    "\"\"\"\n",
    "Interpretation:\n",
    "\n",
    "The two-sample t-test yielded a t-statistic of -3.03 and a p-value of 0.0027, indicating that there \n",
    "is a significant difference in test scores between the control and experimental groups. Specifically,\n",
    "the experimental group had a mean score that was 4.79 points higher than the control group.\n",
    "\n",
    "To follow up on this result, we conducted a post-hoc test using Tukey's HSD method, which compares all \n",
    "pairs of group means to determine which, if any, differ significantly from each other. The results of \n",
    "the post-hoc test indicate that the experimental group had a significantly higher mean score than the\n",
    "control group (reject=True).\n",
    "\"\"\"\n",
    "# Access the attributes\n",
    "groups = tukey_results.groupsunique\n",
    "meandiffs = tukey_results.meandiffs\n",
    "pvalues = tukey_results.pvalues\n",
    "reject = tukey_results.reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6d3f008-34c6-40e5-bb03-b6525a26f736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 19.710498049475664\n",
      "p-value: 8.70867222411767e-08\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      "group1 group2 meandiff p-adj   lower    upper   reject\n",
      "------------------------------------------------------\n",
      "     A      B 109.6771 0.0013  38.0754 181.2789   True\n",
      "     A      C 187.6449    0.0 116.0431 259.2467   True\n",
      "     B      C  77.9678 0.0295    6.366 149.5696   True\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nInterpretation:\\n\\nThe one-way ANOVA  indicates that\\nthere is a significant difference in daily sales between the three stores. To follow up on this\\nresult, we conducted a post-hoc test using Tukey's HSD method, which compares all pairs of group \\nmeans to determine which, if any, differ significantly from each other. The results of the post-hoc \\ntest indicate that all pairwise comparisons are significant (reject=True), indicating that all three\\nstores have significantly different mean daily sale.\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 12\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(123)\n",
    "store_a_sales = np.random.normal(loc=1000, scale=100, size=30)\n",
    "store_b_sales = np.random.normal(loc=1100, scale=100, size=30)\n",
    "store_c_sales = np.random.normal(loc=1200, scale=100, size=30)\n",
    "\n",
    "# Combine the data into a single DataFrame\n",
    "data = pd.DataFrame({'sales': np.concatenate((store_a_sales, store_b_sales, store_c_sales)),\n",
    "                     'store': ['A']*30 + ['B']*30 + ['C']*30})\n",
    "\n",
    "# Conduct one-way ANOVA\n",
    "f, p = stats.f_oneway(store_a_sales, store_b_sales, store_c_sales)\n",
    "print(\"F-statistic:\", f)\n",
    "print(\"p-value:\", p)\n",
    "\n",
    "if p< 0.05:\n",
    "    # Conduct post-hoc test (Tukey's HSD)\n",
    "    tukey_results = pairwise_tukeyhsd(data['sales'], data['store'])\n",
    "    print(tukey_results)\n",
    "\"\"\"\n",
    "Interpretation:\n",
    "\n",
    "The one-way ANOVA  indicates that\n",
    "there is a significant difference in daily sales between the three stores. To follow up on this\n",
    "result, we conducted a post-hoc test using Tukey's HSD method, which compares all pairs of group \n",
    "means to determine which, if any, differ significantly from each other. The results of the post-hoc \n",
    "test indicate that all pairwise comparisons are significant (reject=True), indicating that all three\n",
    "stores have significantly different mean daily sale.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
