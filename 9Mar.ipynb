{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1462b787-f160-4c38-9bdd-49bc32b14cd4",
   "metadata": {},
   "source": [
    "# Stats 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b11f7d38-5709-4e08-b742-5472da9a69c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=\"9MarInfo.log\", level=logging.INFO, format=\"%(asctime)s %(name)s %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75ee8151-f97d-41a3-9590-75c03ea1f27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe Probability Mass Function (PMF) and Probability Density Function (PDF) are two mathematical concepts used to describe the\\nprobability distribution of a random variable.\\n\\nThe PMF is used to describe the probability distribution of a discrete random variable. It is defined as the function that \\nmaps each possible value of the random variable to its probability. That is, for a discrete random variable X, the PMF is given by:\\n\\nP(X = x) = f(x)\\n\\nwhere f(x) is the probability that X takes on the value x.\\n\\nFor example, suppose we toss a fair coin twice and let X be the number of heads that appear. Then, X is a discrete random variable\\nthat takes on the values 0, 1, or 2 with probabilities given by:\\n\\nP(X = 0) = 1/4, P(X = 1) = 1/2, P(X = 2) = 1/4\\n\\nThis is an example of a PMF.\\n\\nOn the other hand, the PDF is used to describe the probability distribution of a continuous random variable. It is defined as \\nthe function that gives the probability density at each point in the support of the random variable. That is, for a continuous\\nrandom variable X, the PDF is given by:\\n\\nf(x) = dF(x)/dx\\n\\nwhere F(x) is the cumulative distribution function of X.\\n\\nFor example, suppose we have a continuous random variable X that is uniformly distributed over the interval [0,1]. Then, the PDF of X is given by:\\n\\nf(x) = 1, for 0 <= x <= 1\\nf(x) = 0, otherwise\\n\\nThis is an example of a PDF.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 1\n",
    "\"\"\"\n",
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are two mathematical concepts used to describe the\n",
    "probability distribution of a random variable.\n",
    "\n",
    "The PMF is used to describe the probability distribution of a discrete random variable. It is defined as the function that \n",
    "maps each possible value of the random variable to its probability. That is, for a discrete random variable X, the PMF is given by:\n",
    "\n",
    "P(X = x) = f(x)\n",
    "\n",
    "where f(x) is the probability that X takes on the value x.\n",
    "\n",
    "For example, suppose we toss a fair coin twice and let X be the number of heads that appear. Then, X is a discrete random variable\n",
    "that takes on the values 0, 1, or 2 with probabilities given by:\n",
    "\n",
    "P(X = 0) = 1/4, P(X = 1) = 1/2, P(X = 2) = 1/4\n",
    "\n",
    "This is an example of a PMF.\n",
    "\n",
    "PDF is used to describe the probability distribution of a continuous random variable. It is defined as \n",
    "the function that gives the probability density at each point in the support of the random variable. That is, for a continuous\n",
    "random variable X, the PDF is given by:\n",
    "\n",
    "f(x) = dF(x)/dx\n",
    "\n",
    "where F(x) is the cumulative distribution function of X.\n",
    "\n",
    "For example, suppose we have a continuous random variable X that is uniformly distributed over the interval [0,1]. Then, the PDF of X is given by:\n",
    "\n",
    "f(x) = 1, for 0 <= x <= 1\n",
    "f(x) = 0, otherwise\n",
    "\n",
    "This is an example of a PDF.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d95e9d5-f071-401d-b01f-8e5d0a2b084e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe Cumulative Density Function (CDF) is a mathematical function used to describe the probability distribution of a random variable.\\nIt gives the probability that the random variable X takes on a value less than or equal to x, for all possible values of x.\\n\\nThe CDF of a random variable X is denoted as F(x) and is defined as:\\n\\nF(x) = P(X <= x)\\n\\nwhere P(X <= x) is the probability that X takes on a value less than or equal to x.\\n\\nFor example, suppose we have a discrete random variable X that takes on the values 1, 2, 3, and 4 with probabilities given by:\\n\\nP(X = 1) = 0.1, P(X = 2) = 0.2, P(X = 3) = 0.3, P(X = 4) = 0.4\\n\\nThe CDF of X is:\\n\\nF(x) = P(X <= x) =\\n0 for x < 1\\n0.1 for 1 <= x < 2\\n0.3 for 2 <= x < 3\\n0.6 for 3 <= x < 4\\n1 for x >= 4\\n\\nThe CDF can be used to determine the probability that X takes on a value in a certain interval. For example, the probability that \\nX takes on a value between 2 and 4 is:\\n\\nP(2 <= X <= 4) = F(4) - F(1) = 1 - 0.1 = 0.9\\n\\nThe CDF is also useful for calculating other statistical quantities such as the median, quartiles, and percentiles of a random variable.\\n\\nOverall, the CDF is an important concept in probability theory and statistics, as it provides a complete description of the probability \\ndistribution of a random variable.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 2\n",
    "\"\"\"\n",
    "The Cumulative Density Function (CDF) is a mathematical function used to describe the probability distribution of a random variable.\n",
    "It gives the probability that the random variable X takes on a value less than or equal to x, for all possible values of x.\n",
    "\n",
    "The CDF of a random variable X is denoted as F(x) and is defined as:\n",
    "\n",
    "F(x) = P(X <= x)\n",
    "\n",
    "where P(X <= x) is the probability that X takes on a value less than or equal to x.\n",
    "\n",
    "For example, suppose we have a discrete random variable X that takes on the values 1, 2, 3, and 4 with probabilities given by:\n",
    "\n",
    "P(X = 1) = 0.1, P(X = 2) = 0.2, P(X = 3) = 0.3, P(X = 4) = 0.4\n",
    "\n",
    "The CDF of X is:\n",
    "\n",
    "F(x) = P(X <= x) =\n",
    "0 for x < 1\n",
    "0.1 for 1 <= x < 2\n",
    "0.3 for 2 <= x < 3\n",
    "0.6 for 3 <= x < 4\n",
    "1 for x >= 4\n",
    "\n",
    "The CDF can be used to determine the probability that X takes on a value in a certain interval. For example, the probability that \n",
    "X takes on a value between 2 and 4 is:\n",
    "\n",
    "P(2 <= X <= 4) = F(4) - F(1) = 1 - 0.1 = 0.9\n",
    "\n",
    "The CDF is also useful for calculating other statistical quantities such as the median, quartiles, and percentiles of a random variable.\n",
    "\n",
    "Overall, the CDF is an important concept in probability theory and statistics, as it provides a complete description of the probability \n",
    "distribution of a random variable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14b19512-bd40-45ae-bb17-a3f225b7e11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe normal distribution is a commonly used statistical distribution in many fields, including science, engineering, social sciences, and\\nfinance. It is used to model continuous random variables whose values are influenced by many small, independent, and identically distributed factors.\\n\\nSome examples of situations where the normal distribution might be used as a model include:\\n\\nHeights of people in a population\\nWeights of manufactured products\\nScores on standardized tests such as the SAT or ACT\\nLengths of leaves on a plant species\\nReaction times of athletes\\nThe normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean of a normal distribution \\nrepresents the center of the distribution and determines the location of the peak of the bell-shaped curve. The standard deviation of a\\nnormal distribution measures the spread or variability of the distribution, with larger values of σ indicating a wider distribution.\\n\\nThe shape of the normal distribution is symmetric, with the mean and median being equal. The percentage of observations within a certain\\nnumber of standard deviations from the mean is fixed, which makes the normal distribution a convenient and widely applicable model in many \\nsituations. Specifically, about 68% of the observations fall within one standard deviation of the mean, about 95% of the observations \\nfall within two standard deviations of the mean, and about 99.7% of the observations fall within three standard deviations of the mean.\\nThis property of the normal distribution, known as the empirical rule or the 68-95-99.7 rule, is very useful in statistical inference \\nand hypothesis testing.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 3\n",
    "\"\"\"\n",
    "The normal distribution is a commonly used statistical distribution in many fields, including science, engineering, social sciences, and\n",
    "finance. It is used to model continuous random variables whose values are influenced by many small, independent, and identically distributed factors.\n",
    "\n",
    "Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "Heights of people in a population\n",
    "Weights of manufactured products\n",
    "Scores on standardized tests such as the SAT or ACT\n",
    "Lengths of leaves on a plant species\n",
    "Reaction times of athletes\n",
    "The normal distribution is characterized by two parameters: the mean (μ) and the standard deviation (σ). The mean of a normal distribution \n",
    "represents the center of the distribution and determines the location of the peak of the bell-shaped curve. The standard deviation of a\n",
    "normal distribution measures the spread or variability of the distribution, with larger values of σ indicating a wider distribution.\n",
    "\n",
    "The shape of the normal distribution is symmetric, with the mean and median being equal. The percentage of observations within a certain\n",
    "number of standard deviations from the mean is fixed, which makes the normal distribution a convenient and widely applicable model in many \n",
    "situations. Specifically, about 68% of the observations fall within one standard deviation of the mean, about 95% of the observations \n",
    "fall within two standard deviations of the mean, and about 99.7% of the observations fall within three standard deviations of the mean.\n",
    "This property of the normal distribution, known as the empirical rule or the 68-95-99.7 rule, is very useful in statistical inference \n",
    "and hypothesis testing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9e7bf93-3bd6-4e89-b56c-5f058ce3ff5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe normal distribution is important in statistics and data analysis for several reasons:\\n\\nIt is a widely applicable model: The normal distribution can be used to model many real-world phenomena, making it a useful tool \\nfor a wide range of applications. Many naturally occurring phenomena, such as heights and weights of people, are well approximated\\nby the normal distribution.\\n\\nIt has a simple and well-understood mathematical structure: The normal distribution is mathematically tractable, meaning that it \\ncan be easily described and analyzed using standard statistical techniques. This makes it a convenient tool for statistical inference\\nand hypothesis testing.\\n\\nIt is an important assumption in many statistical tests: Many statistical tests, such as t-tests and ANOVA, assume that the data are\\nnormally distributed. Violating this assumption can lead to inaccurate or misleading results.\\n\\nIt is related to the Central Limit Theorem: The normal distribution is related to the Central Limit Theorem, which states that the \\nsum or average of a large number of independent and identically distributed random variables will be approximately normally distributed,\\nregardless of the underlying distribution of the individual variables.\\n\\nReal-life examples of normal distribution include:\\n\\nHeights and weights of people: The distribution of heights and weights of adults in a population is approximately normal, with the\\nmean and standard deviation varying by age, sex, and other factors.\\n\\nTest scores: The scores on many standardized tests, such as the SAT and ACT, are approximately normally distributed.\\n\\nStock prices: The daily returns of many stocks are approximately normally distributed, making it a useful tool for modeling and\\npredicting stock prices.\\n\\nReaction times: The distribution of reaction times of athletes or drivers can be approximated by the normal distribution.\\n\\nMeasured physical quantities: The distribution of errors or uncertainties in measured physical quantities, such as length, mass, or time, \\ncan be modeled by a normal distribution.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 4\n",
    "\"\"\"\n",
    "The normal distribution is important in statistics and data analysis for several reasons:\n",
    "\n",
    "It is a widely applicable model: The normal distribution can be used to model many real-world phenomena, making it a useful tool \n",
    "for a wide range of applications. Many naturally occurring phenomena, such as heights and weights of people, are well approximated\n",
    "by the normal distribution.\n",
    "\n",
    "It has a simple and well-understood mathematical structure: The normal distribution is mathematically tractable, meaning that it \n",
    "can be easily described and analyzed using standard statistical techniques. This makes it a convenient tool for statistical inference\n",
    "and hypothesis testing.\n",
    "\n",
    "It is an important assumption in many statistical tests: Many statistical tests, such as t-tests and ANOVA, assume that the data are\n",
    "normally distributed. Violating this assumption can lead to inaccurate or misleading results.\n",
    "\n",
    "It is related to the Central Limit Theorem: The normal distribution is related to the Central Limit Theorem, which states that the \n",
    "sum or average of a large number of independent and identically distributed random variables will be approximately normally distributed,\n",
    "regardless of the underlying distribution of the individual variables.\n",
    "\n",
    "Real-life examples of normal distribution include:\n",
    "\n",
    "Heights and weights of people: The distribution of heights and weights of adults in a population is approximately normal, with the\n",
    "mean and standard deviation varying by age, sex, and other factors.\n",
    "\n",
    "Test scores: The scores on many standardized tests, such as the SAT and ACT, are approximately normally distributed.\n",
    "\n",
    "Stock prices: The daily returns of many stocks are approximately normally distributed, making it a useful tool for modeling and\n",
    "predicting stock prices.\n",
    "\n",
    "Reaction times: The distribution of reaction times of athletes or drivers can be approximated by the normal distribution.\n",
    "\n",
    "Measured physical quantities: The distribution of errors or uncertainties in measured physical quantities, such as length, mass, or time, \n",
    "can be modeled by a normal distribution.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eced6768-7ed8-4b89-b530-2bfed4c8bfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe Bernoulli distribution is a discrete probability distribution that models the outcomes of a single binary experiment, \\nwhere the outcome can be either a success (with probability p) or a failure (with probability 1-p). The Bernoulli distribution\\nis named after the Swiss mathematician Jacob Bernoulli, who studied the distribution in the 17th century.\\n\\nAn example of the Bernoulli distribution is the outcome of a coin flip, where the probability of getting heads is p and the probability \\nof getting tails is 1-p. Another example is the outcome of a single roll of a fair die, where the probability of getting a six is p=1/6 \\nand the probability of getting any other number is 1-p=5/6.\\n\\nThe Bernoulli distribution is a special case of the binomial distribution, which models the number of successes in a fixed number of \\nindependent and identical Bernoulli trials. The main difference between the Bernoulli distribution and the binomial distribution is \\nthat the Bernoulli distribution models the outcome of a single trial, while the binomial distribution models the total number of successes\\nin multiple trials.\\n\\nTo be more specific, the binomial distribution assumes a fixed number n of independent and identical Bernoulli trials, each with probability\\nof success p. The binomial distribution gives the probability of getting k successes in n trials, and is given by the formula:\\n\\nP(X=k) = (n choose k) * p^k * (1-p)^(n-k)\\n\\nwhere (n choose k) is the binomial coefficient, which gives the number of ways of choosing k items out of n. The mean and variance of \\nthe binomial distribution are given by:\\n\\nE(X) = np\\nVar(X) = np(1-p)\\n\\nThus, the Bernoulli distribution is a special case of the binomial distribution, where n=1. The mean and variance of the Bernoulli\\ndistribution are given by:\\n\\nE(X) = p\\nVar(X) = p(1-p)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 5\n",
    "\"\"\"\n",
    "The Bernoulli distribution is a discrete probability distribution that models the outcomes of a single binary experiment, \n",
    "where the outcome can be either a success (with probability p) or a failure (with probability 1-p). The Bernoulli distribution\n",
    "is named after the Swiss mathematician Jacob Bernoulli, who studied the distribution in the 17th century.\n",
    "\n",
    "An example of the Bernoulli distribution is the outcome of a coin flip, where the probability of getting heads is p and the probability \n",
    "of getting tails is 1-p. Another example is the outcome of a single roll of a fair die, where the probability of getting a six is p=1/6 \n",
    "and the probability of getting any other number is 1-p=5/6.\n",
    "\n",
    "The Bernoulli distribution is a special case of the binomial distribution, which models the number of successes in a fixed number of \n",
    "independent and identical Bernoulli trials. The main difference between the Bernoulli distribution and the binomial distribution is \n",
    "that the Bernoulli distribution models the outcome of a single trial, while the binomial distribution models the total number of successes\n",
    "in multiple trials.\n",
    "\n",
    "To be more specific, the binomial distribution assumes a fixed number n of independent and identical Bernoulli trials, each with probability\n",
    "of success p. The binomial distribution gives the probability of getting k successes in n trials, and is given by the formula:\n",
    "\n",
    "P(X=k) = (n choose k) * p^k * (1-p)^(n-k)\n",
    "\n",
    "where (n choose k) is the binomial coefficient, which gives the number of ways of choosing k items out of n. The mean and variance of \n",
    "the binomial distribution are given by:\n",
    "\n",
    "E(X) = np\n",
    "Var(X) = np(1-p)\n",
    "\n",
    "Thus, the Bernoulli distribution is a special case of the binomial distribution, where n=1. The mean and variance of the Bernoulli\n",
    "distribution are given by:\n",
    "\n",
    "E(X) = p\n",
    "Var(X) = p(1-p)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de743cb3-1413-44ab-9066-122c6056d7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo find the probability that a randomly selected observation from a normal distribution with mean μ=50 and standard deviation σ=10\\nwill be greater than 60, we need to use the standard normal distribution and transform the original distribution to a standard normal\\ndistribution with mean 0 and standard deviation 1.\\n\\nThe standard normal distribution has a mean of 0 and a standard deviation of 1, and we can transform a random variable X from a normal\\ndistribution with mean μ and standard deviation σ to a standard normal variable Z by using the formula:\\n\\nZ = (X - μ) / σ\\n\\nIn this case, we want to find the probability that X > 60, so we can transform this to a standard normal variable by using:\\n\\nZ = (60 - 50) / 10 = 1\\n\\nNow, we can use a standard normal distribution table or calculator to find the probability that Z > 1. This probability corresponds \\nto the area under the standard normal curve to the right of Z=1.\\n\\nUsing a standard normal distribution table, we can find that the probability of Z > 1 is approximately 0.1587.\\n\\nTherefore, the probability that a randomly selected observation from the given normal distribution is greater than 60 is approximately 0.1587.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 6\n",
    "\"\"\"\n",
    "To find the probability that a randomly selected observation from a normal distribution with mean μ=50 and standard deviation σ=10\n",
    "will be greater than 60, we need to use the standard normal distribution and transform the original distribution to a standard normal\n",
    "distribution with mean 0 and standard deviation 1.\n",
    "\n",
    "The standard normal distribution has a mean of 0 and a standard deviation of 1, and we can transform a random variable X from a normal\n",
    "distribution with mean μ and standard deviation σ to a standard normal variable Z by using the formula:\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "In this case, we want to find the probability that X > 60, so we can transform this to a standard normal variable by using:\n",
    "\n",
    "Z = (60 - 50) / 10 = 1\n",
    "\n",
    "Now, we can use a standard normal distribution table or calculator to find the probability that Z > 1. This probability corresponds \n",
    "to the area under the standard normal curve to the right of Z=1.\n",
    "50%+34.13%=84.13%\n",
    "Therefore P(Z>1)= 100-84.13=15.87%\n",
    "\n",
    "Using a standard normal distribution table, we can find that the probability of Z > 1 is approximately 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from the given normal distribution is greater than 60 is \n",
    "approximately 0.1587 or 15.87%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4979266-64e2-4964-9fe4-e0af49d7b765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe uniform distribution is a continuous probability distribution that models random variables that are equally likely to take on any\\nvalue within a given interval. In other words, the probability density function of the uniform distribution is constant within the \\ninterval and zero outside the interval.\\n\\nAn example of the uniform distribution is the rolling of a fair die. The outcomes of rolling a die are equally likely to be any number \\nfrom 1 to 6, and each outcome has a probability of 1/6. The probability density function of the uniform distribution in this case is:\\n\\nf(x) = 1/6, for 1 <= x <= 6\\nf(x) = 0, otherwise\\n\\nThis means that any outcome from 1 to 6 has an equal probability of 1/6, and any outcome outside this range has a probability of 0. \\nThe cumulative distribution function of the uniform distribution is given by:\\n\\nF(x) = 0, for x < 1\\nF(x) = (x - 1) / 6, for 1 <= x <= 6\\nF(x) = 1, for x > 6\\n\\nThis means that the probability of getting a value less than or equal to x is given by F(x). For example, the probability of rolling\\na number less than or equal to 3 is:\\n\\nF(3) = (3 - 1) / 6 = 1/3\\n\\nThe mean and variance of the uniform distribution are given by:\\n\\nMean = (a + b) / 2\\nVariance = (b - a)^2 / 12\\n\\nwhere a and b are the lower and upper bounds of the interval, respectively. For the example of rolling a die, the mean and variance\\nof the uniform distribution are:\\n\\nMean = (1 + 6) / 2 = 3.5\\nVariance = (6 - 1)^2 / 12 = 2.92\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 7\n",
    "\"\"\"\n",
    "The uniform distribution is a continuous probability distribution that models random variables that are equally likely to take on any\n",
    "value within a given interval. In other words, the probability density function of the uniform distribution is constant within the \n",
    "interval and zero outside the interval.\n",
    "\n",
    "An example of the uniform distribution is the rolling of a fair die. The outcomes of rolling a die are equally likely to be any number \n",
    "from 1 to 6, and each outcome has a probability of 1/6. The probability density function of the uniform distribution in this case is:\n",
    "\n",
    "f(x) = 1/6, for 1 <= x <= 6\n",
    "f(x) = 0, otherwise\n",
    "\n",
    "This means that any outcome from 1 to 6 has an equal probability of 1/6, and any outcome outside this range has a probability of 0. \n",
    "The cumulative distribution function of the uniform distribution is given by:\n",
    "\n",
    "F(x) = 0, for x < 1\n",
    "F(x) = (x - 1) / 6, for 1 <= x <= 6\n",
    "F(x) = 1, for x > 6\n",
    "\n",
    "This means that the probability of getting a value less than or equal to x is given by F(x). For example, the probability of rolling\n",
    "a number less than or equal to 3 is:\n",
    "\n",
    "F(3) = (3 - 1) / 6 = 1/3\n",
    "\n",
    "The mean and variance of the uniform distribution are given by:\n",
    "\n",
    "Mean = (a + b) / 2\n",
    "Variance = (b - a)^2 / 12\n",
    "\n",
    "where a and b are the lower and upper bounds of the interval, respectively. For the example of rolling a die, the mean and variance\n",
    "of the uniform distribution are:\n",
    "\n",
    "Mean = (1 + 6) / 2 = 3.5\n",
    "Variance = (6 - 1)^2 / 12 = 2.92\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d29fa687-c0f6-4826-9feb-65604a8ef3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe z-score, also known as the standard score, is a measure of how many standard deviations a data point is away from the mean of a normal \\ndistribution. It is calculated by subtracting the mean from the data point and then dividing the result by the standard deviation:\\n\\nz = (x - μ) / σ\\n\\nwhere x is the data point, μ is the mean, and σ is the standard deviation.\\n\\nThe importance of the z-score lies in its ability to standardize data and allow for comparisons between different normal distributions. \\nBy converting data to z-scores, we can compare data from different normal distributions with different means and standard deviations on\\na common scale. This is useful in statistical analysis and hypothesis testing, where we often need to compare data from different sources \\nor populations.\\n\\nIn addition, the z-score can be used to determine the probability of a data point occurring in a normal distribution. This is because \\nthe z-score corresponds to the area under the standard normal distribution curve to the left or right of the data point. By using a \\nstandard normal distribution table or calculator, we can find the probability of a data point occurring in a normal distribution, given its z-score.\\n\\nOverall, the z-score is an important tool in statistics for standardizing data and making comparisons between different normal distributions.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 8\n",
    "\"\"\"\n",
    "The z-score, also known as the standard score, is a measure of how many standard deviations a data point is away from the mean of a normal \n",
    "distribution. It is calculated by subtracting the mean from the data point and then dividing the result by the standard deviation:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the data point, μ is the mean, and σ is the standard deviation.\n",
    "\n",
    "The importance of the z-score lies in its ability to standardize data and allow for comparisons between different normal distributions. \n",
    "By converting data to z-scores, we can compare data from different normal distributions with different means and standard deviations on\n",
    "a common scale. This is useful in statistical analysis and hypothesis testing, where we often need to compare data from different sources \n",
    "or populations.\n",
    "\n",
    "In addition, the z-score can be used to determine the probability of a data point occurring in a normal distribution. This is because \n",
    "the z-score corresponds to the area under the standard normal distribution curve to the left or right of the data point. By using a \n",
    "standard normal distribution table or calculator, we can find the probability of a data point occurring in a normal distribution, given its z-score.\n",
    "\n",
    "Overall, the z-score is an important tool in statistics for standardizing data and making comparisons between different normal distributions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41a71b21-8195-40d9-8135-f5d6a5d9a1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of the sample mean of a random variable.\\nIt states that as the sample size increases, the distribution of the sample means approaches a normal distribution, regardless of the shape\\nof the population distribution.\\n\\nMore specifically, the CLT states that the sample mean of a large enough sample size (n ≥ 30) drawn from any population with a finite mean (μ) \\nand finite variance (σ^2) will be approximately normally distributed with a mean of μ and a standard deviation of σ/√n. This means that as\\nthe sample size increases, the sample mean becomes a more reliable estimate of the population mean.\\n\\nThe significance of the CLT lies in its practical applications in statistics. It allows us to make statistical inferences about a population \\nbased on a sample, even if the population distribution is unknown or non-normal. It also helps us to understand the behavior of the sample mean,\\nand to determine the sampling distribution of the mean for different sample sizes.\\n\\nThe CLT is used extensively in hypothesis testing, confidence interval estimation, and statistical modeling. It is also important in fields such\\nas economics, finance, and engineering, where large sample sizes are often required to make reliable predictions or decisions.\\n\\nOverall, the Central Limit Theorem is a fundamental concept in statistics that helps us to understand the behavior of sample means and make \\nreliable inferences about populations based on samples. It is an important tool for anyone working with data analysis or statistical modeling.\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 9\n",
    "\"\"\"\n",
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of the sample mean of a random variable.\n",
    "It states that as the sample size increases, the distribution of the sample means approaches a normal distribution, regardless of the shape\n",
    "of the population distribution.\n",
    "\n",
    "More specifically, the CLT states that the sample mean of a large enough sample size (n ≥ 30) drawn from any population with a finite mean (μ) \n",
    "and finite variance (σ^2) will be approximately normally distributed with a mean of μ and a standard deviation of σ/√n. This means that as\n",
    "the sample size increases, the sample mean becomes a more reliable estimate of the population mean.\n",
    "\n",
    "The significance of the CLT lies in its practical applications in statistics. It allows us to make statistical inferences about a population \n",
    "based on a sample, even if the population distribution is unknown or non-normal. It also helps us to understand the behavior of the sample mean,\n",
    "and to determine the sampling distribution of the mean for different sample sizes.\n",
    "\n",
    "The CLT is used extensively in hypothesis testing, confidence interval estimation, and statistical modeling. It is also important in fields such\n",
    "as economics, finance, and engineering, where large sample sizes are often required to make reliable predictions or decisions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c14bb94-390e-479e-a4a7-8ad84e85f694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of the sample mean of a random variable. \\nIn order for the CLT to be applicable, certain assumptions must be met:\\n\\nRandom Sampling: The sample must be drawn at random from the population. This means that every individual in the population has an equal\\nchance of being selected.\\n\\nIndependence: Each observation in the sample must be independent of each other. This means that the value of one observation does not \\naffect the value of any other observation.\\n\\nFinite Population or Large Sample: The population from which the sample is drawn must be finite or the sample size must be sufficiently large. \\nA commonly used rule of thumb is that the sample size should be at least 30.\\n\\nFinite Mean and Variance: The population must have a finite mean (μ) and finite variance (σ^2).\\n\\nSampling with Replacement: If sampling is done with replacement, the population must be sufficiently large such that the probability of \\nselecting the same individual twice is negligible.\\n\\nThese assumptions are important because they ensure that the sample is representative of the population, and that the sample mean will be \\nnormally distributed as the sample size increases. If these assumptions are not met, the CLT may not be applicable, and alternative methods\\nof statistical inference may need to be used.\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 10\n",
    "\"\"\"\n",
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the behavior of the sample mean of a random variable. \n",
    "In order for the CLT to be applicable, certain assumptions must be met:\n",
    "\n",
    "Random Sampling: The sample must be drawn at random from the population. This means that every individual in the population has an equal\n",
    "chance of being selected.\n",
    "\n",
    "Independence: Each observation in the sample must be independent of each other. This means that the value of one observation does not \n",
    "affect the value of any other observation.\n",
    "\n",
    "Finite Population or Large Sample: The population from which the sample is drawn must be finite or the sample size must be sufficiently large. \n",
    "A commonly used rule of thumb is that the sample size should be at least 30.\n",
    "\n",
    "Finite Mean and Variance: The population must have a finite mean (μ) and finite variance (σ^2).\n",
    "\n",
    "Sampling with Replacement: If sampling is done with replacement, the population must be sufficiently large such that the probability of \n",
    "selecting the same individual twice is negligible.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
