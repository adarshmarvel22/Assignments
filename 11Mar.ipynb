{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f720abac-2695-453e-8550-0a994294bf0d",
   "metadata": {},
   "source": [
    "# Stats 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee914e-231c-43ef-a846-76cf22a6388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=\"11MarInfo.log\", level=logging.INFO, format=\"%(asctime)s %(name)s %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73b51a-93f2-4689-a884-b1dfed43303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer 1\n",
    "\"\"\"\n",
    "A t-test and a z-test are both statistical tests used to determine if a sample mean is significantly different from a population mean.\n",
    "However, the two tests are used in different scenarios.\n",
    "\n",
    "A z-test is used when the population standard deviation is known and the sample size is large. A t-test, is used \n",
    "when the population standard deviation is unknown and the sample size is small (typically less than 30).\n",
    "\n",
    "For example, suppose we want to test whether the mean weight of a population of apples is 5 ounces. If we have a large sample size \n",
    "(let's say n = 100) and we know the population standard deviation (let's say σ = 0.5 ounces), we can use a z-test.\n",
    "However, if we only have a small sample size (let's say n = 10) and we don't know the population standard deviation, we would use a t-test.\n",
    "\n",
    "Another example could be testing the effectiveness of a new medication in reducing blood pressure. If the sample size is large\n",
    "and the population standard deviation of blood pressure is known, a z-test can be used to compare the mean blood pressure of patients\n",
    "who received the medication to those who received a placebo. However, if the sample size is small and the population standard deviation of\n",
    "blood pressure is unknown, a t-test should be used.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a92d5-687b-4c91-ba18-a1d887e49eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer 2\n",
    "\"\"\"\n",
    "A hypothesis test can be either a one-tailed or two-tailed test, depending on the nature of the research question and the direction\n",
    "of the expected difference or effect.\n",
    "\n",
    "In a two-tailed test, the null hypothesis states that there is no significant difference or effect, while the alternative \n",
    "hypothesis states that there is a significant difference or effect, but it does not specify the direction of the effect. \n",
    "Therefore, a two-tailed test is used when we are interested in detecting any significant difference or effect, regardless\n",
    "of whether it is positive or negative. The level of significance is typically split equally between both tails of the distribution,\n",
    "so the rejection region is divided into two equal parts.\n",
    "\n",
    "For example, a researcher may want to test whether the mean score of a group of students on a test is significantly different from\n",
    "the population mean score of 75. The null hypothesis would be that there is no significant difference between the two means, \n",
    "while the alternative hypothesis would be that there is a significant difference. A two-tailed test would be appropriate because \n",
    "the researcher is interested in detecting any difference, regardless of whether it is higher or lower than the population mean score.\n",
    "\n",
    "In a one-tailed test, the null hypothesis states that there is no significant difference or effect, while the alternative hypothesis\n",
    "specifies the direction of the effect. Therefore, a one-tailed test is used when we are interested in detecting a significant difference \n",
    "or effect in a specific direction, either positive or negative. The level of significance is concentrated in one tail of the distribution,\n",
    "and the rejection region is located entirely in that tail.\n",
    "\n",
    "For example, a researcher may want to test whether a new teaching method leads to an improvement in test scores compared to the traditional\n",
    "teaching method. The null hypothesis would be that there is no significant difference between the two methods, while the alternative hypothesis\n",
    "would be that the new method leads to higher test scores. A one-tailed test would be appropriate because the researcher is interested in detecting\n",
    "only an improvement in test scores, not a decline.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b22d6f-3ad0-438f-bcfe-0b1f44430b6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer 3\n",
    "\"\"\"\n",
    "In hypothesis testing, we compare a null hypothesis with an alternative hypothesis to determine whether to reject or fail to\n",
    "reject the null hypothesis. However, there is always a risk of making an incorrect decision, which is called a Type 1 or Type 2 error.\n",
    "\n",
    "A Type 1 error occurs when we reject a null hypothesis that is actually true. In other words, we conclude that there is a significant \n",
    "effect or difference when there is actually none. The probability of making a Type 1 error is denoted by alpha (α), which is the level\n",
    "of significance we choose for the test. A smaller alpha level reduces the risk of Type 1 error but increases the risk of Type 2 error.\n",
    "\n",
    "For example, suppose we conduct a study to test whether a new drug is effective in treating a particular disease. The null hypothesis \n",
    "is that the drug has no effect on the disease, while the alternative hypothesis is that the drug is effective. If we reject the null\n",
    "hypothesis and conclude that the drug is effective when it is actually not, we make a Type 1 error. This could lead to the drug being\n",
    "approved and marketed, causing harm to patients and wasting resources.\n",
    "\n",
    "A Type 2 error occurs when we fail to reject a null hypothesis that is actually false. In other words, we conclude that there is no \n",
    "significant effect or difference when there is actually one. The probability of making a Type 2 error is denoted by beta (β), which is\n",
    "affected by factors such as sample size, effect size, and variability of the data. A smaller beta level reduces the risk of Type 2 error \n",
    "but increases the risk of Type 1 error.\n",
    "\n",
    "For example, suppose we conduct a study to test whether a new teaching method improves student performance in a subject. The null hypothesis \n",
    "is that there is no difference in performance between the new method and the traditional method, while the alternative hypothesis is that the\n",
    "new method leads to higher performance. If we fail to reject the null hypothesis and conclude that there is no difference when there is\n",
    "actually one, we make a Type 2 error. This could lead to the continued use of the traditional method, missing out on potential benefits \n",
    "of the new method.\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8d9cd-e04c-4919-bc7b-172a7da9c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer 4\n",
    "\"\"\"\n",
    "Bayes's theorem is a mathematical formula that helps us update our beliefs about the probability of an event occurring based\n",
    "on new evidence or information. It is named after Reverend Thomas Bayes, an 18th-century statistician who developed the formula.\n",
    "\n",
    "The formula for Bayes's theorem is:\n",
    "\n",
    "P(A|B) = P(B|A) x P(A) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A|B) is the probability of event A given that event B has occurred\n",
    "P(B|A) is the probability of event B given that event A has occurred\n",
    "P(A) is the prior probability of event A occurring\n",
    "P(B) is the prior probability of event B occurring\n",
    "To understand Bayes's theorem better, let's consider an example:\n",
    "\n",
    "Suppose a certain disease affects 1% of the population. A medical test for this disease has a 95% accuracy rate (i.e., \n",
    "it correctly identifies 95% of people with the disease and 95% of people without the disease). If a person tests positive for the disease,\n",
    "what is the probability that they actually have the disease?\n",
    "\n",
    "Let's use Bayes's theorem to answer this question.\n",
    "\n",
    "P(A) = 0.01 (the prior probability of having the disease)\n",
    "P(B|A) = 0.95 (the probability of testing positive given that the person has the disease)\n",
    "P(B|~A) = 0.05 (the probability of testing positive given that the person does not have the disease)\n",
    "P(~A) = 0.99 (the prior probability of not having the disease)\n",
    "\n",
    "Using Bayes's theorem, we can calculate:\n",
    "\n",
    "P(A|B) = P(B|A) x P(A) / P(B) = 0.95 x 0.01 / ((0.95 x 0.01) + (0.05 x 0.99)) = 0.161\n",
    "\n",
    "Therefore, if a person tests positive for the disease, the probability that they actually have the disease is only 16.1%, despite the \n",
    "high accuracy of the test. This is because the disease is rare, and there is a high false positive rate, meaning that many people without\n",
    "the disease will still test positive.\n",
    "\n",
    "Bayes's theorem can be a powerful tool for updating our beliefs based on new information, and it is widely used in fields such as medicine,\n",
    "finance, and artificial intelligence.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3333937b-b391-479a-acca-67f1cc3d6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer 5\n",
    "\"\"\"\n",
    "A confidence interval is a range of values that is likely to contain the true value of a population parameter with a certain degree \n",
    "of confidence or probability. It is used to estimate the precision or accuracy of a sample statistic, such as a mean or proportion, \n",
    "based on a random sample from a larger population.\n",
    "\n",
    "The confidence interval is calculated based on the sample statistic, the standard error of the statistic, and the chosen level of \n",
    "confidence, which is usually expressed as a percentage. For example, a 95% confidence interval means that if we were to take many \n",
    "random samples from the same population, 95% of the intervals we construct would contain the true population parameter.\n",
    "\n",
    "To calculate a confidence interval, we need to follow these steps:\n",
    "\n",
    "Calculate the sample statistic, such as the mean or proportion.\n",
    "Calculate the standard error of the statistic, which is a measure of the variability of the statistic across different samples. \n",
    "The formula for the standard error depends on the type of statistic and the sampling distribution, but it typically involves the\n",
    "sample size and the population standard deviation or variance.\n",
    "Determine the level of confidence, such as 90%, 95%, or 99%.\n",
    "Look up the critical value from a standard normal distribution or a t-distribution, depending on the sample size and whether the\n",
    "population standard deviation is known. The critical value corresponds to the number of standard errors from the mean that covers\n",
    "the desired level of confidence. For example, for a 95% confidence interval, the critical value is approximately 1.96 for a large \n",
    "sample size (n > 30) or a known population standard deviation, and t(0.025, df) for a small sample size (n < 30) or an unknown \n",
    "population standard deviation, where t is the t-distribution and df is the degrees of freedom.\n",
    "Calculate the lower and upper bounds of the confidence interval by adding and subtracting the product of the critical value and \n",
    "the standard error from the sample statistic. The lower bound is the sample statistic minus the margin of error, and the upper \n",
    "bound is the sample statistic plus the margin of error.\n",
    "Here is an example of how to calculate a confidence interval for a sample mean:\n",
    "\n",
    "Suppose we want to estimate the average weight of all adult men in a certain city. We take a random sample of 50 men and measure \n",
    "their weights. The sample mean is 175 pounds, and the sample standard deviation is 10 pounds. We want to construct a 95% confidence\n",
    "interval for the population mean weight.\n",
    "\n",
    "Using the formula for the standard error of the mean, we have:\n",
    "\n",
    "SE = s / sqrt(n) = 10 / sqrt(50) = 1.41\n",
    "\n",
    "The critical value for a 95% confidence interval with 49 degrees of freedom is t(0.025, 49) = 2.009.\n",
    "\n",
    "The margin of error is:\n",
    "\n",
    "ME = t(0.025, 49) x SE = 2.009 x 1.41 = 2.84\n",
    "\n",
    "The 95% confidence interval is therefore:\n",
    "\n",
    "175 - 2.84 < mu < 175 + 2.84\n",
    "\n",
    "or\n",
    "\n",
    "172.16 < mu < 177.84\n",
    "\n",
    "We can interpret this interval as follows: we are 95% confident that the true population mean weight of adult men in the city lies \n",
    "between 172.16 pounds and 177.84 pounds.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6741ce-f0ec-4d17-99b2-5fef56371559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following function will find CI with significance level=alpha\n",
    "import math\n",
    "import scipy.stats as stat\n",
    "\n",
    "def estimate_population_mean(sample_mean, sample_std, sample_size,alpha):\n",
    "    # Calculate the standard error of the mean\n",
    "    standard_error = sample_std / math.sqrt(sample_size)\n",
    "    \n",
    "    # Calculate the margin of error \n",
    "    cv=stat.t.ppf(q=alpha/2,df=sample_size-1)\n",
    "    # print(cv)\n",
    "    margin_of_error = -1*cv * standard_error\n",
    "    \n",
    "    # Calculate the lower and upper bounds of the confidence interval\n",
    "    lower_bound = sample_mean - margin_of_error\n",
    "    upper_bound = sample_mean + margin_of_error\n",
    "    \n",
    "    # Return the estimated population mean and the confidence interval\n",
    "    return (sample_mean, lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d062992-0c23-403e-889c-52e18b9d7dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSure, here's an example problem that uses Bayes' Theorem to update the probability of an event given new evidence:\\n\\nSuppose that a rare disease affects 1 in 1000 people in a certain population. A new test for the disease has been developed,\\nand the test correctly identifies 99% of people who have the disease (true positive rate) and incorrectly identifies 5% of \\npeople who do not have the disease as positive (false positive rate). If a person tests positive for the disease, \\nwhat is the probability that they actually have the disease?\\n\\nTo solve this problem using Bayes' Theorem, we can start by defining the following probabilities:\\n\\nP(D) = probability of having the disease = 1/1000\\nP(D') = probability of not having the disease = 999/1000\\nP(T|D) = probability of testing positive given that the person has the disease (true positive rate) = 0.99\\nP(T|D') = probability of testing positive given that the person does not have the disease (false positive rate) = 0.05\\nWe want to calculate the probability of having the disease given that the person tests positive, which can be expressed as:\\n\\nP(D|T) = probability of having the disease given a positive test result\\n\\nUsing Bayes' Theorem, we can write:\\n\\nP(D|T) = P(T|D) * P(D) / P(T)\\n\\nwhere P(T) is the probability of testing positive, which can be calculated using the law of total probability:\\n\\nP(T) = P(T|D) * P(D) + P(T|D') * P(D')\\n\\nSubstituting the values we have:\\n\\nP(T) = 0.99 * 0.001 + 0.05 * 0.999 = 0.05094\\n\\nNow we can plug in the numbers and solve for P(D|T):\\n\\nP(D|T) = 0.99 * 0.001 / 0.05094 = 0.0194 or approximately 1.94%\\n\\nTherefore, the probability of having the disease given a positive test result is only about 1.94%, even though the test has a 99% \\n  true positive rate. This is because the false positive rate of 5% is relatively high, and the disease is rare in the population.\\n  It is important to keep in mind that diagnostic tests should be evaluated based on their positive and negative predictive values, \\n  which take into account the prevalence of the disease and the performance of the test.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer 6\n",
    "\"\"\"\n",
    "Sure, here's an example problem that uses Bayes' Theorem to update the probability of an event given new evidence:\n",
    "\n",
    "Suppose that a rare disease affects 1 in 1000 people in a certain population. A new test for the disease has been developed,\n",
    "and the test correctly identifies 99% of people who have the disease (true positive rate) and incorrectly identifies 5% of \n",
    "people who do not have the disease as positive (false positive rate). If a person tests positive for the disease, \n",
    "what is the probability that they actually have the disease?\n",
    "\n",
    "To solve this problem using Bayes' Theorem, we can start by defining the following probabilities:\n",
    "\n",
    "P(D) = probability of having the disease = 1/1000\n",
    "P(D') = probability of not having the disease = 999/1000\n",
    "P(T|D) = probability of testing positive given that the person has the disease (true positive rate) = 0.99\n",
    "P(T|D') = probability of testing positive given that the person does not have the disease (false positive rate) = 0.05\n",
    "We want to calculate the probability of having the disease given that the person tests positive, which can be expressed as:\n",
    "\n",
    "P(D|T) = probability of having the disease given a positive test result\n",
    "\n",
    "Using Bayes' Theorem, we can write:\n",
    "\n",
    "P(D|T) = P(T|D) * P(D) / P(T)\n",
    "\n",
    "where P(T) is the probability of testing positive, which can be calculated using the law of total probability:\n",
    "\n",
    "P(T) = P(T|D) * P(D) + P(T|D') * P(D')\n",
    "\n",
    "Substituting the values we have:\n",
    "\n",
    "P(T) = 0.99 * 0.001 + 0.05 * 0.999 = 0.05094\n",
    "\n",
    "Now we can plug in the numbers and solve for P(D|T):\n",
    "\n",
    "P(D|T) = 0.99 * 0.001 / 0.05094 = 0.0194 or approximately 1.94%\n",
    "\n",
    "Therefore, the probability of having the disease given a positive test result is only about 1.94%, even though the test has a 99% \n",
    "  true positive rate. This is because the false positive rate of 5% is relatively high, and the disease is rare in the population.\n",
    "  It is important to keep in mind that diagnostic tests should be evaluated based on their positive and negative predictive values, \n",
    "  which take into account the prevalence of the disease and the performance of the test.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c285c3-f4bb-4d90-bbf0-4f0ced2f2f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound of the CI is: 49.02\n",
      "The upper bound of the CI is: 50.98\n"
     ]
    }
   ],
   "source": [
    "# answer 7\n",
    "\"\"\"\n",
    "To calculate the 95% confidence interval for a sample of data with a mean of 50 and a standard deviation of 5, we can use the following formula:\n",
    "\n",
    "Confidence interval = X̄ ± Zα/2 * (σ/√n)\n",
    "\n",
    "where X̄ is the sample mean, σ is the population standard deviation (which we estimate using the sample standard deviation in this case),\n",
    "n is the sample size, Zα/2 is the Z-score that corresponds to the desired level of confidence (in this case, 95%), and √n is the square \n",
    "root of the sample size.\n",
    "\n",
    "Since we know that the sample mean is 50, the sample standard deviation is 5, and we want a 95% confidence interval, we can look up the \n",
    "Z-score for the 97.5th percentile (since we want to split the remaining 5% into the tails of the distribution) in a standard normal \n",
    "distribution table or use a calculator, which is 1.96.\n",
    "\n",
    "Plugging in the values:\n",
    "\n",
    "Confidence interval = 50 ± 1.96 * (5/√n)\n",
    "\n",
    "We don't know the sample size n, so let's assume a sample size of 100 for the purposes of this example. Then:\n",
    "\n",
    "Confidence interval = 50 ± 1.96 * (5/√100)\n",
    "Confidence interval = 50 ± 0.98\n",
    "\n",
    "Interpreting the results, we can say that we are 95% confident that the true population mean falls within the range of 49.02 to 50.98.\n",
    "In other words, if we were to repeat the sampling process many times and calculate the confidence interval for each sample, we would \n",
    "expect that about 95% of the intervals would contain the true population mean. Note that this does not mean that there is a 95% probability \n",
    "that the true population mean falls within this specific interval, since the population mean is a fixed value and not a random variable.\n",
    "\"\"\"\n",
    "import math\n",
    "import scipy.stats as stat\n",
    "\n",
    "def estimate_population_mean(sample_mean, sample_std, sample_size,alpha):\n",
    "    # Calculate the standard error of the mean\n",
    "    standard_error = sample_std / math.sqrt(sample_size)\n",
    "    \n",
    "    # Calculate the margin of error \n",
    "    cv=stat.norm.ppf(q=alpha/2)\n",
    "    # print(cv)\n",
    "    margin_of_error = -1*cv * standard_error\n",
    "    \n",
    "    # Calculate the lower and upper bounds of the confidence interval\n",
    "    lower_bound = sample_mean - margin_of_error\n",
    "    upper_bound = sample_mean + margin_of_error\n",
    "    \n",
    "    # Return the estimated population mean and the confidence interval\n",
    "    return (sample_mean, lower_bound, upper_bound)\n",
    "\n",
    "# We don't know the sample size n, so let's assume a sample size of 100 for the purposes of this example:\n",
    "sample_size=100\n",
    "sample_mean=50\n",
    "sample_std=5\n",
    "alpha=0.05\n",
    "ans=estimate_population_mean(sample_mean, sample_std, sample_size,alpha)\n",
    "\n",
    "print(\"The lower bound of the CI is:\",round(ans[1],4))\n",
    "print(\"The upper bound of the CI is:\",round(ans[2],4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fb8e31-551e-446e-95d8-a08c783e38eb",
   "metadata": {},
   "source": [
    "# answer 8\n",
    "\"\"\"\n",
    "The margin of error is a measure of the precision of an estimated population parameter in a sample. It is the range of values that is likely to include the true population parameter with a certain degree of confidence. A confidence interval is typically expressed as an interval estimate of the population parameter with a given level of confidence.\n",
    "\n",
    "The margin of error is determined by several factors, including the size of the sample, the level of confidence desired, and the variability of the data. The larger the sample size, the smaller the margin of error, assuming all other factors remain constant. This is because a larger sample size results in a more accurate estimate of the population parameter and reduces the effect of sampling error.\n",
    "\n",
    "For example, suppose a pollster wants to estimate the proportion of voters who support a particular candidate in an election. If the pollster takes a small sample of 100 voters, the margin of error might be +/- 10%, which means that the true proportion of voters who support the candidate is likely to be within the range of 40% to 60% with 95% confidence. However, if the pollster takes a larger sample of 1000 voters, the margin of error might be +/- 3%, which means that the true proportion of voters who support the candidate is likely to be within the range of 47% to 53% with 95% confidence.\n",
    "\n",
    "In this example, the larger sample size results in a smaller margin of error, which provides a more precise estimate of the population parameter.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2604f68b-a7b6-40c9-8ee9-804878c10f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area to the left of z = 1.0 is 0.1587\n"
     ]
    }
   ],
   "source": [
    "# answer 9\n",
    "\"\"\"\n",
    "The z-score for a data point represents how many standard deviations away from the population mean that data point is. \n",
    "The formula for calculating the z-score is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the value of the data point, μ is the population mean, and σ is the population standard deviation.\n",
    "\n",
    "Using the given values, we can calculate the z-score as:\n",
    "\n",
    "z = (75 - 70) / 5 = 1\n",
    "\n",
    "This means that the data point with a value of 75 is one standard deviation above the population mean of 70. \n",
    "The positive value of the z-score indicates that the data point is above the population mean. We can also use a z-table or\n",
    "calculator to find the area under the standard normal distribution curve to the right of the z-score of 1, which gives the\n",
    "probability of observing a value as extreme or more extreme than 75 in the population. The area is approximately 0.1587 or 15.87%.\n",
    "\"\"\"\n",
    "from scipy.stats import norm\n",
    "\n",
    "x=75\n",
    "mu=70\n",
    "pop_std=5\n",
    "\n",
    "z=(x-mu)/pop_std\n",
    "\n",
    "area_left = norm.cdf(z)\n",
    "area_right=1-area_left\n",
    "print(\"Area to the left of z =\", z, \"is\", round(area_right, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2f4e7-b91e-4b73-b95e-2f1dd9aa1f4f",
   "metadata": {},
   "source": [
    "# answer 10\n",
    "We will use a one-sample t-test to test the hypothesis, since we are comparing the sample mean to a known population mean (0). \n",
    "\n",
    "### State the null and alternative hypotheses\n",
    "Null hypothesis (H0): The population mean weight loss is equal to 0 pounds (i.e., the drug is not effective).\n",
    "Alternative hypothesis (Ha): The population mean weight loss is less than 0 pounds (i.e., the drug is effective).\n",
    "\n",
    "### Set the level of significance:\n",
    "alpha=0.05\n",
    "\n",
    "### Select the appropriate test:\n",
    "one-tailed t-test with a significance level of 0.05. \n",
    "\n",
    "### Determine the test statistic:\n",
    "t_score and t_stats\n",
    "\n",
    "### Calculate the p-value:\n",
    "p_value from z or t score(here in this question from t_score)\n",
    "\n",
    "### Make a decision:\n",
    "If the p-value is less than the level of significance, reject the null hypothesis. If the p-value is greater than the level of significance, fail to reject \n",
    "the null hypothesis.\n",
    "Also if t_stat < critical value we reject the null hypotheses\n",
    "\n",
    "### Interpret the results: \n",
    "If the null hypothesis is rejected, it means there is sufficient evidence to support the alternative hypothesis. If the null hypothesis is not rejected, \n",
    "it means there is not enough evidence to support the alternative hypothesis.\n",
    "\n",
    "### Draw conclusions: \n",
    "The conclusions drawn from the test should be based on the results and the research question being addressed. It is important to interpret the results in \n",
    "the context of the study and to consider the limitations of the data and the test used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1387d40a-ed9b-4906-9d55-466046c93d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the Null Hypothesis: \n",
      " The drug is effective and is less than 0 pounds(effective)\n"
     ]
    }
   ],
   "source": [
    "# answer 10\n",
    "import scipy.stats as stat\n",
    "import math\n",
    "\n",
    "n=50\n",
    "x=6\n",
    "mu=0\n",
    "samp_std=2.5\n",
    "\n",
    "alpha=0.05\n",
    "df=n-1\n",
    "\n",
    "# t value\n",
    "t=(x-mu)/(samp_std/math.sqrt(n))\n",
    "\n",
    "# critical value\n",
    "cv=stat.t.ppf(q=1-alpha,df=df)\n",
    "\n",
    "if t > cv:\n",
    "    print(\"Reject the Null Hypothesis: \\n The drug is effective and is less than 0 pounds(effective)\")\n",
    "else:\n",
    "    print(\"Failed to reject the Null Hypothesis \\n  The drug is not effective\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67d793c2-a6a4-4b42-9b51-aeb817f6bd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we can say with 95% confidence that the true proportion of people who are satisfied with their job lies between: 0.6081925393809212 0.6918074606190788\n"
     ]
    }
   ],
   "source": [
    "# answer 11\n",
    "\"\"\"\n",
    "To calculate the 95% confidence interval for the true proportion of people who are satisfied with their job, we can use the following formula:\n",
    "\n",
    "CI = p ± z* (sqrt(p*(1-p)/n))\n",
    "\n",
    "where CI is the confidence interval, p is the sample proportion, z* is the z-score associated with the desired confidence level (95% in this case),\n",
    "and n is the sample size.\n",
    "\n",
    "p = 0.65 (sample proportion)\n",
    "n = 500 (sample size)\n",
    "z* = 1.96 (from the standard normal distribution for a 95% confidence level)\n",
    "\n",
    "Calculating the standard error of the proportion:\n",
    "\n",
    "SE = sqrt(p*(1-p)/n) = sqrt(0.65*0.35/500) = 0.027\n",
    "\n",
    "Now, we can plug in the values into the formula to get the confidence interval:\n",
    "\n",
    "CI = 0.65 ± 1.96*(0.027) = (0.597, 0.703)\n",
    "\n",
    "Therefore, we can say with 95% confidence that the true proportion of people who are satisfied with their job lies between 0.597 and 0.703.\n",
    "\"\"\"\n",
    "import math\n",
    "import scipy.stats as stat\n",
    "\n",
    "alpha =0.05\n",
    "\n",
    "p = 0.65\n",
    "n = 500\n",
    "# (from the standard normal distribution for a 95% confidence level)\n",
    "z=stat.norm.ppf(alpha/2)\n",
    "\n",
    "side= z*(math.sqrt(p*(1-p)/n))\n",
    "\n",
    "lb=p+side\n",
    "ub=p-side\n",
    "\n",
    "print(\"we can say with 95% confidence that the true proportion of people who are satisfied with their job lies between:\",lb,ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebf6362-d044-4d5e-9f6f-0dddf4c6d477",
   "metadata": {},
   "source": [
    "# answer 12\n",
    "\"\"\"\n",
    "We will use a two-sample t-test to test the hypothesis, since we are comparing the means of two independent samples. The test statistic for\n",
    "a two-sample t-test is:\n",
    "\n",
    "Null hypothesis (H0): There is no significant difference in student performance between the two teaching methods. The true population mean\n",
    "difference is equal to 0.\n",
    "Alternative hypothesis (Ha): There is a significant difference in student performance between the two teaching methods. The true population\n",
    "mean difference is not equal to 0.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "913ad47d-1a96-47b5-88f1-9c9c944ada85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2739508701956017\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "mean1=85\n",
    "mean2=82\n",
    "std1=6\n",
    "std2=5\n",
    "# assuming the values of n1 and n2 since sample sizes are not mentioned\n",
    "nobs1,nobs2=11,11\n",
    "alpha=0.01\n",
    "\n",
    "t_stat,p_val=scipy.stats.ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var=False, alternative='two-sided')\n",
    "\n",
    "if p_val < alpha:\n",
    "    print(\"Reject the Null Hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa5ac392-15e0-4953-bd8e-cff2e901d4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval lies between: 63.13906055411732 66.86093944588268\n"
     ]
    }
   ],
   "source": [
    "# answer 13\n",
    "\"\"\"\n",
    "To calculate the 90% confidence interval for the true population mean, we can use the formula:\n",
    "\n",
    "CI = x̄ ± z*(σ/√n)\n",
    "\n",
    "where x̄ is the sample mean, σ is the population standard deviation, n is the sample size, and z is the z-score corresponding\n",
    "to the desired confidence level.\n",
    "\n",
    "For a 90% confidence interval, the z-score is 1.645 (obtained from a standard normal distribution table or calculator).\n",
    "\n",
    "Substituting the given values, we get:\n",
    "\n",
    "CI = 65 ± 1.645*(8/√50)\n",
    "\n",
    "CI = 65 ± 2.322\n",
    "\n",
    "The 90% confidence interval for the true population mean is (62.678, 67.322).\n",
    "\n",
    "This means that if we repeatedly take samples of the same size from the population and construct 90% confidence intervals, \n",
    "about 90% of these intervals will contain the true population mean.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import scipy.stats as stat\n",
    "\n",
    "alpha =0.10\n",
    "\n",
    "x=65\n",
    "mu=60\n",
    "n = 50\n",
    "pop_std=8\n",
    "# (from the standard normal distribution)\n",
    "z=stat.norm.ppf(alpha/2)\n",
    "\n",
    "margin_err=z*pop_std/(math.sqrt(n))\n",
    "\n",
    "lb=x+margin_err\n",
    "ub=x-margin_err\n",
    "\n",
    "print(\"Confidence Interval lies between:\",lb,ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fac81b-b155-4152-a820-b66fc35f20ab",
   "metadata": {},
   "source": [
    "# answer 14\n",
    "To conduct a hypothesis test to determine if the caffeine has a significant effect on reaction time at a 90%\n",
    "confidence level, we can use a two-tailed t-test with the null hypothesis:\n",
    "\n",
    "### State the null and alternative hypotheses\n",
    "H0: μ = 0.25 (caffeine has no effect on reaction time)\n",
    "\n",
    "And the alternative hypothesis:\n",
    "\n",
    "Ha: μ ≠ 0.25 (caffeine has a significant effect on reaction time)\n",
    "\n",
    "### Set the level of significance:\n",
    "alpha=0.01\n",
    "\n",
    "### Select the appropriate test:\n",
    "one-tailed t-test with a significance level of 0.01. \n",
    "\n",
    "### Determine the test statistic:\n",
    "t_score and t_stats\n",
    "\n",
    "### Calculate the p-value:\n",
    "p_value from z or t score(here in this question from t_score)\n",
    "\n",
    "### Make a decision:\n",
    "If the p-value is less than the level of significance, reject the null hypothesis. If the p-value is greater than the level\n",
    "of significance, fail to reject the null hypothesis.\n",
    "\n",
    "### Interpret the results: \n",
    "If the null hypothesis is rejected, it means there is sufficient evidence to support the alternative hypothesis. If the null \n",
    "hypothesis is not rejected, it means there is not enough evidence to support the alternative hypothesis.\n",
    "\n",
    "### Draw conclusions: \n",
    "The conclusions drawn from the test should be based on the results and the research question being addressed. It is important \n",
    "to interpret the results in the context of the study and to consider the limitations of the data and the test used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba920942-833e-46e2-aa39-9322258b2d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "We fail to reject the null hypothesis \n",
      " caffeine has no effect on reaction time\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "sample_mean = 0.25\n",
    "sample_std = 0.05\n",
    "n = 30\n",
    "alpha = 0.1 # 90% confidence level\n",
    "\n",
    "t_critical = t.ppf(alpha/2, n-1)\n",
    "std_error = sample_std / np.sqrt(n)\n",
    "\n",
    "t_value = (sample_mean - 0.25) / std_error\n",
    "\n",
    "p_value = 2 * (1 - t.cdf(abs(t_value), n-1))\n",
    "print(t_value)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"We reject the null hypothesis \\n caffeine has a significant effect on reaction time\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis \\n caffeine has no effect on reaction time\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
